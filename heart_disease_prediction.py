# -*- coding: utf-8 -*-
"""heart_disease_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k76ppQuEtR9g_xeoLL7kHf-Hyo6gpxJz
"""

import pandas as pd
import numpy as np
import seaborn as sns
sns.set_theme()
import matplotlib.pyplot as plt
# Use a single data path so the script runs both locally and outside Colab
DATA_PATH = r"C:\Users\pravi\OneDrive\Documents\ML_Project\heart_statlog_cleveland_hungary_final.csv"
data=pd.read_csv(DATA_PATH)
df=pd.DataFrame(data)
df.columns

df

df.dtypes

df.loc[df['chest pain type'] == 1, 'chest pain type'] = 'typical angina'
df.loc[df['chest pain type'] == 2, 'chest pain type'] = 'atypical angina'
df.loc[df['chest pain type'] == 3, 'chest pain type'] = 'non-anginal pain'
df.loc[df['chest pain type'] == 4, 'chest pain type'] = 'asymptomatic'



df.loc[df['resting ecg'] == 0, 'resting ecg'] = 'normal'
df.loc[df['resting ecg'] == 1, 'resting ecg'] = 'ST-T wave abnormality'
df.loc[df['resting ecg'] == 2, 'resting ecg'] = 'left ventricular hypertrophy'

df.loc[df['ST slope'] == 0, 'ST slope'] = 'normal'
df.loc[df['ST slope'] == 1, 'ST slope'] = 'upsloping'
df.loc[df['ST slope'] == 2, 'ST slope'] = 'flat'
df.loc[df['ST slope'] == 3, 'ST slope'] = 'downsloping'

df["sex"] = df.sex.apply(lambda  x:'male' if x==1 else 'female')
df

df.dtypes

df.info()

df.isna()

df.isna().sum()

shap=df.shape
print(f'Number of rows: {shap[0]} and Number of columns: {shap[1]}')

df.describe(include =[np.number])

fig = plt.figure(figsize=(9,5))
sns.set_style('whitegrid')
ax = sns.countplot(x=df['target'], hue=df['target'],data = df,palette ='cool', legend=False)

plt.title('No. of Heart disease patients in Dataset',weight='bold',fontsize=14,)

for i in ax.containers:
    ax.bar_label(i,)

fig = plt.figure(figsize=(9,5))
ax = sns.countplot(x=df['sex'],hue=df['sex'],data = df,palette ='cool', legend=False)

ax.set_title('Gender wise distribution',weight = 'bold',fontsize=14)

for i in ax.containers:
    ax.bar_label(i,)

fig = plt.figure(figsize=(9,5))
sns.set_style('whitegrid')
df['age'].hist(bins=30,color='blue',alpha=0.5)

plt.xlabel('age')
plt.title("Age wise distribution",weight = 'bold',fontsize=14)

fig = plt.figure(figsize=(9,5))
sns.set_style('whitegrid')
sns.displot(df[df['target']==1]['age'],alpha=0.5,color='red',kde=True)

plt.title('Age wise distribution for Heart disease patients',weight = 'bold',fontsize=12)

attr_1=df[df['target']==1]
attr_0=df[df['target']==0]
fig = plt.figure(figsize=(15,5))
ax1 = plt.subplot2grid((1,2),(0,0))
sns.histplot(attr_0['age'])
plt.title('AGE DISTRIBUTION OF NORMAL PATIENTS', fontsize=15, weight='bold')

ax1 = plt.subplot2grid((1,2),(0,1))
sns.countplot(x='sex', data=attr_0,  hue='sex')
plt.title('GENDER DISTRIBUTION OF NORMAL PATIENTS', fontsize=15, weight='bold' )
plt.show()

fig = plt.figure(figsize=(15,5))
ax1 = plt.subplot2grid((1,2),(0,0))
sns.histplot(attr_1['age'])
plt.title('AGE DISTRIBUTION OF HEART DISEASE PATIENTS', fontsize=15, weight='bold')

ax1 = plt.subplot2grid((1,2),(0,1))
sns.countplot(x='sex', data=attr_1, hue='sex')
plt.title('GENDER DISTRIBUTION OF HEART DISEASE PATIENTS', fontsize=15, weight='bold' )
plt.show()

fig, ax = plt.subplots(figsize=(10,4))
# Horizontal Bar Plot
title_cnt=df['chest pain type'].value_counts().sort_values(ascending=False).reset_index()
mn= ax.barh(title_cnt.iloc[:,0], title_cnt.iloc[:,1], color='silver')
mn[0].set_color('lightskyblue')
mn[3].set_color('crimson')


# Add Plot Title
ax.set_title('Chest Pain type Distribution', loc='center', pad=10, fontsize=16)
plt.yticks(weight='bold')


# Add annotation to bars
for i in ax.patches:
    ax.text(i.get_width()+10, i.get_y()+0.5, str(round((i.get_width()), 2)),
            fontsize=10, fontweight='bold', color='grey')
plt.yticks(weight='bold')
plt.xticks(weight='bold')
# Show Plot
plt.show()


fig, ax = plt.subplots(figsize=(10,4))
# Horizontal Bar Plot
title_cnt=attr_1['chest pain type'].value_counts().sort_values(ascending=False).reset_index()
mn= ax.barh(title_cnt.iloc[:,0], title_cnt.iloc[:,1], color='silver')
mn[0].set_color('red')
mn[3].set_color('blue')

# Add Plot Title
ax.set_title('Chest Pain type Distribution of Heart patients',
             loc='center', pad=10, fontsize=16)
plt.yticks(weight='bold')


# Add annotation to bars
for i in ax.patches:
    ax.text(i.get_width()+10, i.get_y()+0.5, str(round((i.get_width()), 2)),
            fontsize=10, fontweight='bold', color='grey')
plt.yticks(weight='bold')
plt.xticks(weight='bold')
# Show Plot
plt.show()

plot_criteria= ['chest pain type', 'target']
cm = sns.light_palette("red", as_cmap=True)
(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)

df['target']=df['target'].replace({0: 'No heart attack', 1: 'Heart attack'})
df=df[::-1]
plt.figure(figsize=(30, 20))
sorted_x1 = df['age'].value_counts().index.sort_values()
sns.countplot(x='age', hue='target', data=df, order=sorted_x1)
plt.xticks(rotation=90)
plt.title('Stacked Bar Chart')
plt.show()

selected_columns = ['age']
plot_criteria = [selected_columns[0], 'target']
cm = sns.light_palette("red", as_cmap=True)
cross_tab = pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100
styled_table = cross_tab.round(2).style.background_gradient(cmap=cm)
styled_table

cnames=['age','resting bp s','cholesterol','max heart rate','ST slope','oldpeak']
f, ax = plt.subplots(figsize=(7, 5))

#Correlation plot
df_corr = data.loc[:,cnames]
#Generate correlation matrix
corr = df_corr.corr()

#Plot using seaborn library
sns.heatmap(corr, annot = True, cmap='coolwarm',linewidths=.1)
plt.show()

df_corr = data.loc[:,cnames]
df_corr

from sklearn.model_selection import train_test_split

predictors = data.drop("target",axis=1)
target = data["target"]

X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=0)
print("Training features have {0} records and Testing features have {1} records.".\
      format(X_train.shape[0], X_test.shape[0]))

import pandas as pd
import numpy as np
import warnings
from sklearn.model_selection import train_test_split, GridSearchCV
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler

# Ensure we load the same dataset when running locally (fix for Colab path)
data = pd.read_csv(DATA_PATH)

# Specify the features and target
features = ['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol',
            'fasting blood sugar', 'resting ecg', 'max heart rate', 'exercise angina',
            'oldpeak', 'ST slope']
y = data['target']

# Encoding categorical features using OneHotEncoder
categorical_features = ['sex', 'chest pain type', 'exercise angina']
data = pd.get_dummies(data, columns=categorical_features, drop_first=True)

# Create feature matrix X
X = data[data.columns.difference(['target'])].copy()

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale numerical features
scaler = StandardScaler()
numerical_features = ['age', 'resting bp s', 'cholesterol', 'max heart rate', 'oldpeak']
X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

warnings.filterwarnings("ignore", category=UserWarning)

# Initialize the XGBoost model
model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

# Define hyperparameters for tuning
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1.0]
}

# Hyperparameter tuning with GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3)
grid_search.fit(X_train, y_train)

# Make predictions with the best model
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy * 100:.2f}%')

# Additional classification report
print(classification_report(y_test, y_pred))

# Prepare input data for prediction
input_data = (70,1,2,190,280,0,0,150,0,0.0,2)
input_df = pd.DataFrame([input_data], columns=features)

# One-hot encode the input data
input_df = pd.get_dummies(input_df, columns=categorical_features, drop_first=True)

# Align input data with training features
input_df = input_df.reindex(columns=X_train.columns, fill_value=0)

# Scale numerical features
input_df[numerical_features] = scaler.transform(input_df[numerical_features])

# Make prediction
prediction = best_model.predict(input_df)

# Print prediction result
print("Prediction (0 = no heart disease, 1 = heart disease):", prediction[0])























